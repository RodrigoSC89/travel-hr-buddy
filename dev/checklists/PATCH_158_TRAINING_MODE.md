# PATCH 158.0 ‚Äì AI Training Mode & Copilot Precision
**Status:** ‚úÖ READY FOR VALIDATION  
**Objetivo:** Validar precis√£o da IA treinadora e copilot  
**Data:** 2025-01-20

---

## üìã Resumo

Implementa√ß√£o e valida√ß√£o do modo de treinamento com IA:
- Crew Copilot com contexto enriquecido
- Respostas precisas baseadas em documenta√ß√£o
- Cache offline para contexto persistente
- Feedback loop para melhoria cont√≠nua
- M√©tricas de precis√£o e satisfa√ß√£o

---

## ‚úÖ Checklist de Valida√ß√£o

### 1. Crew Copilot Functionality
- [ ] Chat interface responsiva
- [ ] Streaming de respostas funcionando
- [ ] Context awareness (hist√≥rico + docs)
- [ ] Offline mode com cache local
- [ ] Online/offline indicator vis√≠vel
- [ ] Mensagens sincronizam ao voltar online

### 2. Precis√£o de Respostas
- [ ] Respostas baseadas em documenta√ß√£o oficial
- [ ] Zero alucina√ß√µes detectadas
- [ ] Cita√ß√µes de fontes quando relevante
- [ ] Resposta em < 3s (streaming)
- [ ] Formata√ß√£o markdown correta
- [ ] Code snippets com syntax highlighting

### 3. Context Enrichment
- [ ] Cache carrega contexto anterior
- [ ] Similaridade sem√¢ntica > 0.7
- [ ] Hist√≥rico limitado a √∫ltimos 20 messages
- [ ] Context window gerenciado (< 32k tokens)
- [ ] Prioriza√ß√£o de mensagens relevantes
- [ ] Metadata preservado (timestamps, mode)

### 4. Training Feedback Loop
- [ ] Thumbs up/down em cada resposta
- [ ] Feedback salvo em banco
- [ ] Analytics de satisfa√ß√£o
- [ ] Reports de baixa qualidade
- [ ] Re-treinamento baseado em feedback
- [ ] A/B testing de prompts

### 5. Performance & Reliability
- [ ] Latency P95 < 5s
- [ ] Uptime > 99%
- [ ] Error rate < 1%
- [ ] Token efficiency > 80%
- [ ] Cache hit rate > 60%
- [ ] Fallback offline funcional

---

## üß™ Cen√°rios de Teste

### Cen√°rio 1: Precis√£o de Conhecimento T√©cnico
**Prompt:** "How do I report a near-miss incident on the vessel?"

**Expected:**
- Resposta menciona m√≥dulo de incidents
- Cita passos espec√≠ficos do sistema
- Inclui screenshot ou link se dispon√≠vel
- Tempo de resposta < 3s
- Zero men√ß√µes a features inexistentes

### Cen√°rio 2: Context Awareness
**Conversation:**
1. User: "What certificates do I need for STCW?"
2. Assistant: [resposta sobre STCW]
3. User: "Where can I upload them?"

**Expected:**
- Resposta #3 entende "them" = certificates
- Menciona m√≥dulo de certifica√ß√µes
- Lembra contexto da pergunta #1
- Cache carrega hist√≥rico completo

### Cen√°rio 3: Offline Resilience
**Steps:**
1. Fazer 3 perguntas online
2. Desconectar internet
3. Fazer 2 perguntas offline
4. Reconectar

**Expected:**
- Mensagens offline marcadas claramente
- Cache fornece contexto mesmo offline
- Sync autom√°tico ao reconectar
- Zero perda de dados

### Cen√°rio 4: Feedback & Learning
**Steps:**
1. Fazer pergunta sobre crewing
2. Receber resposta
3. Dar thumbs down
4. Submeter feedback: "Resposta incompleta"

**Expected:**
- Feedback salvo em `crew_copilot_feedback` table
- Analytics atualizado
- Flag para revis√£o humana
- Prompt ajustado em pr√≥xima vers√£o

---

## üìÇ Arquivos Relacionados

- `src/modules/crew/copilot/index.tsx` ‚Äì Copilot UI
- `src/lib/ai/copilot-cache.ts` ‚Äì Context cache
- `supabase/functions/crew-copilot/index.ts` ‚Äì Edge function
- `src/integrations/supabase/types.ts` ‚Äì DB types
- `dev/checklists/PATCH_146.1_COPILOT_MOBILE.md` ‚Äì Mobile specs

---

## üìä M√©tricas de Sucesso

| M√©trica | Target | Atual | Status |
|---------|--------|-------|--------|
| Response Accuracy | ‚â• 95% | TBD | ‚è≥ |
| Latency P95 | < 5s | TBD | ‚è≥ |
| User Satisfaction | ‚â• 4.5/5 | TBD | ‚è≥ |
| Zero Hallucinations | 100% | TBD | ‚è≥ |
| Cache Hit Rate | ‚â• 60% | TBD | ‚è≥ |
| Offline Success | 100% | TBD | ‚è≥ |
| Context Relevance | ‚â• 0.7 | TBD | ‚è≥ |

---

## üêõ Problemas Conhecidos

1. **Streaming interrompido em mobile**
   - Solu√ß√£o: Implementar retry com exponential backoff
   
2. **Context overflow (> 32k tokens)**
   - Solu√ß√£o: Truncate com prioriza√ß√£o por relev√¢ncia

3. **Cache desatualizado ap√≥s updates**
   - Solu√ß√£o: Versioning de cache com invalida√ß√£o

4. **Latency alta em primeiro request**
   - Solu√ß√£o: Warm-up de contexto no login

---

## ‚úÖ Crit√©rios de Aprova√ß√£o

- [ ] 50 perguntas testadas com 95%+ precis√£o
- [ ] Zero alucina√ß√µes detectadas
- [ ] Feedback loop funcionando end-to-end
- [ ] Offline mode validado em 10 cen√°rios
- [ ] Cache hit rate ‚â• 60%
- [ ] User satisfaction ‚â• 4.5/5 em testes
- [ ] Analytics dashboard mostrando m√©tricas

---

## üìù Notas T√©cnicas

### System Prompt Engineering
```typescript
const SYSTEM_PROMPT = `You are an expert maritime training assistant.

RULES:
1. Only answer based on official documentation provided
2. If unsure, say "I don't have that information"
3. Cite sources when possible
4. Keep answers concise and actionable
5. Use maritime terminology correctly
6. Never hallucinate features or procedures

CONTEXT:
${enrichedContext}

USER HISTORY:
${relevantHistory}
`;
```

### Context Enrichment Algorithm
```typescript
interface ContextConfig {
  maxMessages: 20;
  similarityThreshold: 0.7;
  maxTokens: 32000;
  prioritization: "recency" | "relevance" | "hybrid";
}

function enrichContext(
  currentMessage: string,
  cache: ChatMessage[],
  config: ContextConfig
): string {
  // 1. Filter by similarity
  const relevant = cache.filter(m => 
    cosineSimilarity(m.content, currentMessage) > config.similarityThreshold
  );
  
  // 2. Sort by priority
  const sorted = relevant.sort((a, b) => {
    if (config.prioritization === "recency") {
      return b.timestamp - a.timestamp;
    }
    // ... relevance or hybrid logic
  });
  
  // 3. Truncate to token limit
  return truncateToTokens(sorted, config.maxTokens);
}
```

### Feedback Schema
```sql
CREATE TABLE crew_copilot_feedback (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  message_id UUID REFERENCES crew_copilot_messages(id),
  user_id UUID REFERENCES auth.users(id),
  rating INT CHECK (rating IN (-1, 1)), -- thumbs down/up
  comment TEXT,
  category TEXT, -- 'incorrect' | 'incomplete' | 'irrelevant' | 'excellent'
  created_at TIMESTAMPTZ DEFAULT now()
);
```

### Analytics Queries
```sql
-- Satisfaction score
SELECT 
  AVG(CASE WHEN rating = 1 THEN 5 ELSE 1 END) as avg_rating,
  COUNT(*) as total_feedback
FROM crew_copilot_feedback
WHERE created_at > NOW() - INTERVAL '7 days';

-- Low-quality responses
SELECT 
  m.content as question,
  f.comment as issue,
  f.category
FROM crew_copilot_feedback f
JOIN crew_copilot_messages m ON m.id = f.message_id
WHERE f.rating = -1
ORDER BY f.created_at DESC;
```

---

## üöÄ Pr√≥ximos Passos

1. Criar dataset de 100 perguntas de teste
2. Executar testes de precis√£o
3. Coletar feedback de 20 usu√°rios beta
4. Analisar m√©tricas e identificar gaps
5. Ajustar system prompts baseado em feedback
6. A/B test diferentes estrat√©gias de contexto
7. Deploy para produ√ß√£o com monitoring

---

## üìö Refer√™ncias

- [OpenAI Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)
- [Semantic Search Algorithms](https://www.pinecone.io/learn/semantic-search/)
- [Context Window Management](https://help.openai.com/en/articles/4936856)
- [Lovable AI Documentation](https://docs.lovable.dev/features/ai)
- `/src/modules/crew/copilot/README.md`
