# üï∏Ô∏è IMCA Crawler - Etapa 11

## üéØ Objetivo

Capturar automaticamente os √∫ltimos incidentes p√∫blicos do site oficial da IMCA:

üîó https://www.imca-int.com/safety-events/

E salvar no Supabase na tabela `dp_incidents`.

## üìã Campos da Tabela `dp_incidents`

| Campo | Tipo | Descri√ß√£o |
|-------|------|-----------|
| titulo (title) | text | T√≠tulo do incidente |
| descricao (description) | text | Descri√ß√£o extra√≠da da p√°gina |
| sistema_afetado | text | (Opcional) detectado via NLP ou padr√£o textual |
| gravidade (severity) | text | Alta, M√©dia ou Baixa |
| link_original | text | URL completa da fonte original |
| data_incidente (incident_date) | date | Data de publica√ß√£o do evento |

## üöÄ Como Executar

### 1. Configurar vari√°veis de ambiente

Certifique-se de que o arquivo `.env.local` cont√©m:

```bash
VITE_SUPABASE_URL=https://seu-projeto.supabase.co
SUPABASE_SERVICE_ROLE_KEY=eyJhbGc...seu-service-role-key
```

> ‚ö†Ô∏è **Importante**: O `SUPABASE_SERVICE_ROLE_KEY` √© necess√°rio para opera√ß√µes server-side e bypass de RLS (Row Level Security).

### 2. Executar o crawler

```bash
npm run crawler:imca
```

Ou diretamente:

```bash
npx tsx scripts/imca-crawler.ts
```

### 3. Resultado Esperado

O crawler ir√°:

1. ‚úÖ Acessar https://www.imca-int.com/safety-events/
2. ‚úÖ Extrair informa√ß√µes dos incidentes listados
3. ‚úÖ Verificar duplicatas por `link_original`
4. ‚úÖ Salvar apenas incidentes novos no Supabase
5. ‚úÖ Exibir resumo da execu√ß√£o

Exemplo de sa√≠da:

```
üöÄ Starting IMCA Crawler...

üåê Fetching IMCA safety events from: https://www.imca-int.com/safety-events/
‚úÖ Found 15 incidents on IMCA website

üÜï New incident saved: Loss of Position Due to Gyro Drift
‚è≠Ô∏è  Already exists: Thruster Control Software Failure
üÜï New incident saved: Reference System Failure in Heavy Weather
...

üìä Summary:
   Total incidents found: 15
   New incidents saved: 8
   Duplicates skipped: 7

‚úÖ IMCA Crawler completed successfully!
```

## üìä Visualizar os Dados

Ap√≥s a execu√ß√£o do crawler, os novos incidentes estar√£o dispon√≠veis em:

üîó **Painel**: `/dp-intelligence`

Os incidentes aparecem automaticamente na:
- Tab "Incidentes" - Lista completa de incidentes
- Tab "Dashboard Anal√≠tico" - Estat√≠sticas e gr√°ficos

## ‚öôÔ∏è Executar Periodicamente (Opcional)

Para executar o crawler automaticamente 1x por semana:

### Op√ß√£o 1: Supabase Edge Function com Cron

Crie uma Edge Function:

```typescript
// supabase/functions/imca-crawler-cron/index.ts
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

serve(async (req) => {
  // Execute o mesmo c√≥digo do crawler
  // ...
  return new Response(JSON.stringify({ success: true }), {
    headers: { "Content-Type": "application/json" },
  });
});
```

Configure o cron no dashboard do Supabase para executar semanalmente.

### Op√ß√£o 2: GitHub Actions (Workflow)

Crie um workflow em `.github/workflows/imca-crawler.yml`:

```yaml
name: IMCA Crawler

on:
  schedule:
    - cron: '0 9 * * 1' # Every Monday at 9:00 AM UTC
  workflow_dispatch: # Allow manual trigger

jobs:
  crawler:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '22'
      - run: npm install
      - run: npm run crawler:imca
        env:
          VITE_SUPABASE_URL: ${{ secrets.VITE_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
```

### Op√ß√£o 3: Cron Job Local

Em um servidor Linux, adicione ao crontab:

```bash
# Run every Monday at 9:00 AM
0 9 * * 1 cd /path/to/travel-hr-buddy && npm run crawler:imca
```

## üîß Troubleshooting

### Erro: Missing environment variables

Certifique-se de que as vari√°veis `VITE_SUPABASE_URL` e `SUPABASE_SERVICE_ROLE_KEY` est√£o definidas no `.env.local`.

### Erro: Cannot insert into dp_incidents

Verifique se a migra√ß√£o `20251020000000_add_crawler_fields_to_dp_incidents.sql` foi aplicada:

```bash
# Se usando Supabase CLI local
supabase db push
```

### Nenhum incidente encontrado

O site da IMCA pode ter mudado sua estrutura HTML. Verifique os seletores CSS no arquivo `scripts/imca-crawler.ts`:

- `.news-list__item` - Container de cada incidente
- `.news-list__title` - T√≠tulo do incidente
- `.news-list__date` - Data do incidente

## üìö Depend√™ncias Instaladas

- `axios` - Para fazer requisi√ß√µes HTTP
- `cheerio` - Para parsing de HTML (DOM parsing server-side)
- `tsx` - Para executar TypeScript diretamente
- `@supabase/supabase-js` - Cliente Supabase

## üîê Seguran√ßa

‚ö†Ô∏è **Nunca commite o arquivo `.env.local` no Git!**

O `SUPABASE_SERVICE_ROLE_KEY` tem acesso completo ao banco de dados, incluindo bypass de RLS. Mantenha-o seguro.

## ‚úÖ Pr√≥ximos Passos

Ap√≥s executar o crawler, voc√™ pode:

1. ‚úÖ Visualizar os incidentes no painel `/dp-intelligence`
2. ‚úÖ Aplicar an√°lise de IA nos incidentes (GPT-4)
3. ‚úÖ Criar planos de a√ß√£o automaticamente
4. ‚úÖ Enviar alertas por e-mail para incidentes cr√≠ticos
5. ‚úÖ Integrar com SGSO (Sistema de Gest√£o de Seguran√ßa Operacional)

---

**Desenvolvido para Travel HR Buddy - Sistema N√°utico Inteligente** üö¢‚öì
